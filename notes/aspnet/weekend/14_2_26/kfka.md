
 ## **Full E-Commerce Event-Driven Architecture** using Kafka and microservices**.
 
### ğŸ—ï¸ 1. High-Level Architecture (Event-Driven E-Commerce)

```
Client / Mobile App / Web
          |
      API Gateway
          |
------------------------------------------------
| Order | Payment | Inventory | Shipping | User |
------------------------------------------------
          |
       Apache Kafka (Event Bus)
          |
------------------------------------------------
| Email | Analytics | Refund | Recommendation |
------------------------------------------------
```

ğŸ‘‰ **All communication happens via events.**
ğŸ‘‰ No direct API dependency between core services.

 

###  ğŸ”„ 2. Business Flow (Order â†’ Delivery)

Letâ€™s see what happens when a user buys a product:

###### Step 1: Order Placed

```
Client â†’ Order Service
```

Event:

```
OrderCreated
```

###### Step 2: Payment Processing

```
Payment Service listens â†’ OrderCreated
```

Event:

```
PaymentCompleted
OR
PaymentFailed
```



######  Step 3: Inventory Update

```
Inventory listens â†’ PaymentCompleted
```

Event:

```
StockReserved
OR
OutOfStock
```



######  Step 4: Shipping

```
Shipping listens â†’ StockReserved
```

Event:

```
ShipmentCreated
```



######  Step 5: Notifications

```
Email/SMS listens â†’ All Events
```

Event:

```
NotificationSent
```

### ğŸ§© 3. Core Microservices

| Service      | Responsibility   |
| ------------ | ---------------- |
| Order        | Manages orders   |
| Payment      | Handles payments |
| Inventory    | Manages stock    |
| Shipping     | Delivery         |
| Notification | Email/SMS        |
| Analytics    | Reports          |
| Refund       | Failed orders    |

Each service:

- âœ… Has its own DB
- âœ… Owns its data
- âœ… Communicates via Kafka

### ğŸ“¬ 4. Kafka Topics (Event Channels)

Each business action = Topic

| Topic Name       | Producer  | Consumers          |
| ---------------- | --------- | ------------------ |
| order-created    | Order     | Payment, Analytics |
| payment-success  | Payment   | Inventory          |
| payment-failed   | Payment   | Order, Refund      |
| stock-reserved   | Inventory | Shipping           |
| stock-failed     | Inventory | Order              |
| shipment-created | Shipping  | Notification       |
| order-cancelled  | Order     | Inventory, Refund  |

Example:

```
Topic: order-created
Key: OrderId
Value: JSON Event
```

### ğŸ“¦ 5. Standard Event Format (Contract)

All services follow **same structure**.

```json
{
  "eventId": "uuid",
  "eventType": "OrderCreated",
  "timestamp": "2026-02-14T10:30:00Z",
  "data": {
    "orderId": 501,
    "userId": 10,
    "productId": 2001,
    "quantity": 2,
    "amount": 1500
  }
}
```

This ensures:

- âœ” Versioning
- âœ” Compatibility
- âœ” Debugging
- âœ” Replayability



### ğŸ” 6. Saga Pattern (Distributed Transaction)

In Microservices:

- âŒ No single DB transaction
- âœ… Use **Saga**

##### ğŸŸ¢ Success Flow

```
Order â†’ Payment â†’ Inventory â†’ Shipping â†’ Done
```

All succeed â†’ Order = Confirmed

##### ğŸ”´ Failure Flow (Compensation)

Example: Payment OK, Stock Failed

```
 OrderCreated âœ”
P aymentSuccess âœ”
StockFailed âŒ
```

Compensation:

```
â†’ RefundPayment
â†’ CancelOrder
â†’ RestoreStock
```

###### Compensation Topics

```
refund-requested
order-cancelled
stock-restored
```


### âš™ï¸ 7. Technical Architecture (Inside Each Service)

Every service follows:

```
Controller
   â†“
Application Layer
   â†“
Domain Layer
   â†“
Repository
   â†“
Database
```

Plus:

```
Kafka Producer
Kafka Consumer
```

Example:

```
OrderService
 â”œâ”€â”€ Controllers
 â”œâ”€â”€ Application
 â”œâ”€â”€ Domain
 â”œâ”€â”€ Infrastructure
 â””â”€â”€ Messaging
```

Clean Architecture + Event Driven.


### ğŸ—ƒï¸ 8. Database Strategy (Per Service DB)

| Service   | Database   |
| --------- | ---------- |
| Order     | OrdersDB   |
| Payment   | PaymentDB  |
| Inventory | StockDB    |
| Shipping  | ShippingDB |

â— Never share DB.

Communicate via Events.


### ğŸ›¡ï¸ 9. Reliability & Fault Tolerance

##### âœ… Retry Mechanism

If consumer fails:

```
Retry 3 times â†’ Then DLQ
```

##### âœ… Dead Letter Queue (DLQ)

```
order-created-dlq
payment-failed-dlq
```

Failed messages go here.


##### âœ… Idempotency

Same message processed once:

```csharp
if(Processed(eventId)) return;
```

Avoids duplicates.



##### âœ… Message Replay

Kafka keeps history.

You can replay:

```
Reset Offset â†’ Rebuild Data
```

Very powerful.



### ğŸ“Š 10. Observability Layer

For production:

| Tool    | Purpose      |
| ------- | ------------ |
| Logs    | Debugging    |
| Metrics | Performance  |
| Traces  | Request Flow |

Track:

```
Order â†’ Payment â†’ Inventory â†’ Shipping
```

End-to-end.


### ğŸ” 11. Security Layer

In enterprise:

- âœ… SASL Authentication
- âœ… TLS Encryption
- âœ… OAuth2 Gateway
- âœ… Token Propagation

Kafka secured.


### ğŸš€ 12. Deployment Architecture (Cloud)

```
Kubernetes Cluster
   |
--------------------------------
| Order | Payment | Inventory |
--------------------------------
   |
Kafka Cluster (3+ Brokers)
   |
Monitoring Stack
```

Each service auto-scales independently.



# ğŸ“ 13. Reference Implementation Stack (.NET)

| Layer         | Tech                   |
| ------------- | ---------------------- |
| API           | ASP.NET Core           |
| Messaging     | Kafka                  |
| ORM           | EF Core                |
| Auth          | IdentityServer / OAuth |
| Gateway       | YARP                   |
| Container     | Docker                 |
| Orchestration | Kubernetes             |


### ğŸ“˜ 14. Sample Event Flow (Real Example)

###### Customer Buys Phone

```
1ï¸âƒ£ Order API
â†’ order-created

2ï¸âƒ£ Payment Service
â†’ payment-success

3ï¸âƒ£ Inventory
â†’ stock-reserved

4ï¸âƒ£ Shipping
â†’ shipment-created

5ï¸âƒ£ Notification
â†’ email-sent
```

Final State:

```
Order = Confirmed
Payment = Paid
Stock = Reduced
Shipment = On Way
```

 

### ğŸ§  15. Why This Architecture Works

| Feature       | Benefit           |
| ------------- | ----------------- |
| Event Driven  | Loose coupling    |
| Kafka         | Scalability       |
| Saga          | Data consistency  |
| Microservices | Independent teams |
| Replay        | Disaster recovery |

This is why large platforms use it.


Great. Below is a **complete, end-to-end hands-on project** you can use for **exploring enterprise applicatios**.

This is designed as a **real industry-style E-Commerce Event System** using:

âœ… ASP.NET Core
âœ… Kafka
âœ… Microservices
âœ… Saga Pattern
âœ… Docker
âœ… Clean Architecture


# ğŸš€ PROJECT: Event-Driven E-Commerce System (.NET + Kafka)

## ğŸ¯ What You Will Build

A **mini Amazon-like backend** with 4 services:

```
Order â†’ Payment â†’ Inventory â†’ Notification
```

All connected via Kafka.


## ğŸ—ï¸ Architecture

```
Client (Postman / UI)
      |
   Order API
      |
   Kafka Topics
      |
-------------------------
| Payment | Inventory |
-------------------------
      |
  Notification
```



# ğŸ“ 1. Project Structure

Create one main folder:

```
ECommerceKafkaSystem/
```

Inside:

```
ECommerceKafkaSystem
â”‚
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ OrderService
â”œâ”€â”€ PaymentService
â”œâ”€â”€ InventoryService
â””â”€â”€ NotificationService
```

Each is a separate ASP.NET Web API.



# âš™ï¸ 2. Infrastructure (Kafka + Zookeeper)

Create:

### ğŸ“„ docker-compose.yml

```yaml
version: "3.8"

services:

  zookeeper:
    image: confluentinc/cp-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

Run:

```bash
docker-compose up -d
```


# ğŸ§± 3. Create Microservices

Run:

```bash
dotnet new webapi -n OrderService
dotnet new webapi -n PaymentService
dotnet new webapi -n InventoryService
dotnet new webapi -n NotificationService
```

Install Kafka client in all:

```bash
dotnet add package Confluent.Kafka
```


# ğŸ“¦ 4. Shared Event Contract (IMPORTANT)

Create in **each project**:

### ğŸ“„ Models/EventMessage.cs

```csharp
namespace Shared.Models
{
    public class EventMessage
    {
        public Guid EventId { get; set; }
        public string EventType { get; set; }
        public DateTime Timestamp { get; set; }

        public object Data { get; set; }
    }
}
```

### ğŸ“„ Models/OrderDto.cs

```csharp
namespace Shared.Models
{
    public class OrderDto
    {
        public int OrderId { get; set; }
        public int ProductId { get; set; }
        public int Quantity { get; set; }
        public double Amount { get; set; }
    }
}
```


# ğŸ“¨ 5. Kafka Producer (Reusable)

Create in all services:

### ğŸ“„ Messaging/KafkaProducer.cs

```csharp
using Confluent.Kafka;
using System.Text.Json;

namespace Messaging
{
    public class KafkaProducer
    {
        private readonly IProducer<Null, string> _producer;

        public KafkaProducer()
        {
            var config = new ProducerConfig
            {
                BootstrapServers = "localhost:9092"
            };

            _producer = new ProducerBuilder<Null, string>(config).Build();
        }

        public async Task PublishAsync(string topic, object data)
        {
            var json = JsonSerializer.Serialize(data);

            await _producer.ProduceAsync(topic,
                new Message<Null, string>
                {
                    Value = json
                });
        }
    }
}
```



Register in `Program.cs`:

```csharp
builder.Services.AddSingleton<KafkaProducer>();
```

# ğŸ“¬ 6. Kafka Consumer (Reusable Base)

### ğŸ“„ Messaging/KafkaConsumer.cs

```csharp
using Confluent.Kafka;

namespace Messaging
{
    public abstract class KafkaConsumer : BackgroundService
    {
        protected abstract string Topic { get; }
        protected abstract string GroupId { get; }

        protected override Task ExecuteAsync(CancellationToken stoppingToken)
        {
            return Task.Run(() => Consume(stoppingToken));
        }

        private void Consume(CancellationToken token)
        {
            var config = new ConsumerConfig
            {
                BootstrapServers = "localhost:9092",
                GroupId = GroupId,
                AutoOffsetReset = AutoOffsetReset.Earliest
            };

            using var consumer =
                new ConsumerBuilder<Ignore, string>(config).Build();

            consumer.Subscribe(Topic);

            while (!token.IsCancellationRequested)
            {
                var msg = consumer.Consume(token);

                ProcessMessage(msg.Message.Value);
            }
        }

        protected abstract void ProcessMessage(string message);
    }
}
```


# ğŸ›’ 7. Order Service (Entry Point)

### ğŸ“„ Controllers/OrdersController.cs

```csharp
using Microsoft.AspNetCore.Mvc;
using Messaging;
using Shared.Models;

namespace OrderService.Controllers
{
    [ApiController]
    [Route("api/orders")]
    public class OrdersController : ControllerBase
    {
        private readonly KafkaProducer _producer;

        public OrdersController(KafkaProducer producer)
        {
            _producer = producer;
        }

        [HttpPost]
        public async Task<IActionResult> Create(OrderDto order)
        {
            order.OrderId = Random.Shared.Next(1000, 9999);

            var evt = new EventMessage
            {
                EventId = Guid.NewGuid(),
                EventType = "OrderCreated",
                Timestamp = DateTime.UtcNow,
                Data = order
            };

            await _producer.PublishAsync("order-created", evt);

            return Ok(order);
        }
    }
}
```


# ğŸ’³ 8. Payment Service

### ğŸ“„ Consumers/OrderCreatedConsumer.cs

```csharp
using Messaging;
using System.Text.Json;
using Shared.Models;

namespace PaymentService.Consumers
{
    public class OrderCreatedConsumer : KafkaConsumer
    {
        protected override string Topic => "order-created";
        protected override string GroupId => "payment-group";

        private readonly KafkaProducer _producer;

        public OrderCreatedConsumer(KafkaProducer producer)
        {
            _producer = producer;
        }

        protected override void ProcessMessage(string message)
        {
            var evt = JsonSerializer.Deserialize<EventMessage>(message);

            Console.WriteLine("Payment Processing...");

            var paymentEvt = new EventMessage
            {
                EventId = Guid.NewGuid(),
                EventType = "PaymentSuccess",
                Timestamp = DateTime.UtcNow,
                Data = evt.Data
            };

            _producer.PublishAsync("payment-success", paymentEvt).Wait();
        }
    }
}
```

Register:

```csharp
builder.Services.AddHostedService<OrderCreatedConsumer>();
```


# ğŸ“¦ 9. Inventory Service

### ğŸ“„ Consumers/PaymentSuccessConsumer.cs

```csharp
public class PaymentSuccessConsumer : KafkaConsumer
{
    protected override string Topic => "payment-success";
    protected override string GroupId => "inventory-group";

    private readonly KafkaProducer _producer;

    public PaymentSuccessConsumer(KafkaProducer producer)
    {
        _producer = producer;
    }

    protected override void ProcessMessage(string message)
    {
        Console.WriteLine("Stock Reserved");

        var evt = JsonSerializer.Deserialize<EventMessage>(message);

        var stockEvt = new EventMessage
        {
            EventId = Guid.NewGuid(),
            EventType = "StockReserved",
            Timestamp = DateTime.UtcNow,
            Data = evt.Data
        };

        _producer.PublishAsync("stock-reserved", stockEvt).Wait();
    }
}
```

Register as HostedService.



# ğŸ“§ 10. Notification Service

### ğŸ“„ Consumers/StockConsumer.cs

```csharp
public class StockConsumer : KafkaConsumer
{
    protected override string Topic => "stock-reserved";
    protected override string GroupId => "notification-group";

    protected override void ProcessMessage(string message)
    {
        Console.WriteLine("Email Sent to Customer");
        Console.WriteLine(message);
    }
}
```


# ğŸ”„ 11. Saga (Failure Handling)

Add in Payment:

```csharp
if(Random.Shared.Next(1,10) < 3)
{
   // fail
   Publish("payment-failed");
}
```

Then create:

```
payment-failed â†’ Order â†’ Cancel
```

This implements **compensation**.



# â–¶ï¸ 12. Run Everything

### Start Kafka

```bash
docker-compose up -d
```

### Run Services

4 terminals:

```bash
dotnet run --project OrderService
dotnet run --project PaymentService
dotnet run --project InventoryService
dotnet run --project NotificationService
```



# ğŸ§ª 13. Test (Postman / Curl)

POST:

```
http://localhost:5000/api/orders
```

Body:

```json
{
  "productId": 101,
  "quantity": 2,
  "amount": 1200
}
```



### Output

Order Console:

```
Order Created
```

Payment:

```
Payment Processing
```

Inventory:

```
Stock Reserved
```

Notification:

```
Email Sent
```

ğŸ‰ End-to-end flow complete.

 

# ğŸ“Š 14. Production Add-Ons (Phase 2)

After mastering this, add:

| Feature       | Why         |
| ------------- | ----------- |
| EF Core       | Real DB     |
| Redis         | Caching     |
| DLQ           | Failed msgs |
| Prometheus    | Metrics     |
| OpenTelemetry | Tracing     |
| JWT           | Security    |

 

# ğŸ§  15. What This Project Teaches

This single project covers:

- âœ… Microservices
- âœ… Event Driven
- âœ… Kafka
- âœ… Saga
- âœ… Clean Architecture
- âœ… Async Processing
- âœ… Cloud Readiness

 


 Below is a **complete, classroom-ready Lab Exercise Sheet** you can directly give to your students for practicing **Kafka with ASP.NET Core Microservices (E-Commerce Domain)**.

It is structured like a **professional industry lab manual**.

---

# ğŸ§ª **LAB EXERCISE SHEET**

## Event-Driven E-Commerce using Kafka & ASP.NET Core

---

## ğŸ“Œ Lab Title

**Building Event-Driven Microservices using Apache Kafka and .NET**

---

## ğŸ¯ Learning Objectives

After completing this lab, students will be able to:

âœ” Understand Kafka Producer & Consumer
âœ” Create Topics and Partitions
âœ” Implement Microservice Communication
âœ” Build Event-Driven Workflow
âœ” Apply Saga Pattern (Basic)
âœ” Handle Failures

---

## â±ï¸ Duration

**6 Hours (2 Sessions Ã— 3 Hours)**

---

## ğŸ› ï¸ Tools & Software Required

| Tool                    | Purpose     |
| ----------------------- | ----------- |
| .NET SDK (8+)           | Web API     |
| Docker Desktop          | Kafka Setup |
| Postman                 | API Testing |
| VS Code / Visual Studio | Development |

---

## ğŸ—ï¸ System Architecture

```
Order â†’ Kafka â†’ Payment â†’ Kafka â†’ Inventory â†’ Kafka â†’ Notification
```

---

## ğŸ§© Microservices Used

| Service             | Role              |
| ------------------- | ----------------- |
| OrderService        | Creates Orders    |
| PaymentService      | Processes Payment |
| InventoryService    | Manages Stock     |
| NotificationService | Sends Email       |

---

# ğŸ“ PART A â€” Infrastructure Setup (1 Hour)

---

## ğŸ”¹ Task A1: Install Docker

Verify:

```bash
docker --version
```

---

## ğŸ”¹ Task A2: Setup Kafka

Create:

### docker-compose.yml

```yaml
version: "3"

services:

  zookeeper:
    image: confluentinc/cp-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
```

Run:

```bash
docker-compose up -d
```

---

## âœ… Expected Output

```
Kafka Running on localhost:9092
```

---

# ğŸ“ PART B â€” Create Microservices (1 Hour)

---

## ğŸ”¹ Task B1: Create Projects

```bash
dotnet new webapi -n OrderService
dotnet new webapi -n PaymentService
dotnet new webapi -n InventoryService
dotnet new webapi -n NotificationService
```

---

## ğŸ”¹ Task B2: Install Kafka Client

In all projects:

```bash
dotnet add package Confluent.Kafka
```

---

## ğŸ”¹ Task B3: Verify API

Run:

```bash
dotnet run
```

Open:

```
https://localhost:xxxx/swagger
```

---

## âœ… Expected Output

Swagger UI opens.

---

# ğŸ“ PART C â€” Event Model (45 Min)

---

## ğŸ”¹ Task C1: Create Event Class

In all services:

### Models/EventMessage.cs

```csharp
public class EventMessage
{
    public Guid EventId { get; set; }
    public string EventType { get; set; }
    public DateTime TimeStamp { get; set; }
    public object Data { get; set; }
}
```

---

## ğŸ”¹ Task C2: Create Order DTO

### Models/OrderDto.cs

```csharp
public class OrderDto
{
    public int OrderId { get; set; }
    public int ProductId { get; set; }
    public int Quantity { get; set; }
    public double Amount { get; set; }
}
```

---

# ğŸ“ PART D â€” Kafka Producer (1 Hour)

---

## ğŸ”¹ Task D1: Create Producer Class

### Messaging/KafkaProducer.cs

```csharp
public class KafkaProducer
{
    private readonly IProducer<Null, string> _producer;

    public KafkaProducer()
    {
        var config = new ProducerConfig
        {
            BootstrapServers = "localhost:9092"
        };

        _producer =
            new ProducerBuilder<Null, string>(config).Build();
    }

    public async Task Publish(string topic, object data)
    {
        var json = JsonSerializer.Serialize(data);

        await _producer.ProduceAsync(topic,
            new Message<Null, string> { Value = json });
    }
}
```

---

## ğŸ”¹ Task D2: Register Service

In Program.cs:

```csharp
builder.Services.AddSingleton<KafkaProducer>();
```

---

# ğŸ“ PART E â€” Order Service (45 Min)

---

## ğŸ”¹ Task E1: Create Orders Controller

```csharp
[ApiController]
[Route("api/orders")]
public class OrdersController : ControllerBase
{
    private readonly KafkaProducer _producer;

    public OrdersController(KafkaProducer producer)
    {
        _producer = producer;
    }

    [HttpPost]
    public async Task<IActionResult> Create(OrderDto order)
    {
        order.OrderId = Random.Shared.Next(1000, 9999);

        var evt = new EventMessage
        {
            EventId = Guid.NewGuid(),
            EventType = "OrderCreated",
            TimeStamp = DateTime.UtcNow,
            Data = order
        };

        await _producer.Publish("order-created", evt);

        return Ok(order);
    }
}
```

---

## âœ… Expected Output

Order event published to Kafka.

---

# ğŸ“ PART F â€” Kafka Consumer (1 Hour)

---

## ğŸ”¹ Task F1: Create Base Consumer

### Messaging/KafkaConsumer.cs

```csharp
public abstract class KafkaConsumer : BackgroundService
{
    protected abstract string Topic { get; }
    protected abstract string GroupId { get; }

    protected override Task ExecuteAsync(CancellationToken token)
    {
        return Task.Run(() => Consume(token));
    }

    private void Consume(CancellationToken token)
    {
        var config = new ConsumerConfig
        {
            BootstrapServers = "localhost:9092",
            GroupId = GroupId,
            AutoOffsetReset = AutoOffsetReset.Earliest
        };

        using var consumer =
            new ConsumerBuilder<Ignore, string>(config).Build();

        consumer.Subscribe(Topic);

        while (!token.IsCancellationRequested)
        {
            var msg = consumer.Consume(token);
            Process(msg.Message.Value);
        }
    }

    protected abstract void Process(string message);
}
```

---

## ğŸ”¹ Task F2: Payment Consumer

```csharp
public class OrderConsumer : KafkaConsumer
{
    protected override string Topic => "order-created";
    protected override string GroupId => "payment-group";

    protected override void Process(string message)
    {
        Console.WriteLine("Payment Done");
    }
}
```

Register:

```csharp
builder.Services.AddHostedService<OrderConsumer>();
```

---

## âœ… Expected Output

```
Payment Done
```

---

# ğŸ“ PART G â€” Inventory & Notification (45 Min)

---

## ğŸ”¹ Task G1: Inventory Consumer

Consumes:

```
payment-success
```

Produces:

```
stock-reserved
```

---

## ğŸ”¹ Task G2: Notification Consumer

Consumes:

```
stock-reserved
```

Print:

```
Email Sent
```

---

# ğŸ“ PART H â€” Saga (Failure Handling) (30 Min)

---

## ğŸ”¹ Task H1: Simulate Failure

In Payment:

```csharp
if(Random.Shared.Next(1,5) == 1)
{
   Console.WriteLine("Payment Failed");
}
```

---

## ğŸ”¹ Task H2: Compensation

Create:

```
payment-failed â†’ order-cancelled
```

---

## âœ… Expected Output

System auto-recovers.

---

# ğŸ“Š PART I â€” Testing (30 Min)

---

## ğŸ”¹ Task I1: Post Order

POST:

```
http://localhost:5000/api/orders
```

```json
{
  "productId":201,
  "quantity":2,
  "amount":1500
}
```

---

## ğŸ”¹ Task I2: Observe Logs

Verify:

```
Order â†’ Payment â†’ Inventory â†’ Email
```

---

# ğŸ“ˆ Evaluation Rubric (For Faculty)

| Criteria    | Marks |
| ----------- | ----- |
| Kafka Setup | 20    |
| Producer    | 20    |
| Consumer    | 20    |
| Event Flow  | 20    |
| Saga        | 10    |
| Testing     | 10    |
| Total       | 100   |

---

# ğŸ“š Viva / Review Questions

1. What is Kafka Topic?
2. Why use Partition?
3. What is Consumer Group?
4. Offset meaning?
5. Saga pattern?
6. DLQ purpose?

---

# ğŸ† Mini Project Extension (Optional)

Students may add:

âœ” Database (EF Core)
âœ” JWT Auth
âœ” Dashboard
âœ” Retry Policy

---

# ğŸ“ Instructor Note (For You)

This lab:

âœ… Matches industry workflow
âœ… Builds portfolio project
âœ… Prepares for interviews
âœ… Supports capstone work

 


 # AnserKey

 Letâ€™s understand the **Saga Pattern** in a **mentor-style, industry-relevant way**, exactly how it is used in large systems built by companies like **Netflix** and **Amazon**.

---

# ğŸš€ 1. What Is the Saga Pattern? (In Simple Words)

> **Saga Pattern = Managing transactions across multiple microservices using events instead of a single database transaction.**

In monolithic apps:

âœ… One DB
âœ… One transaction
âœ… Easy rollback

In microservices:

âŒ Many DBs
âŒ No global transaction
âŒ Hard rollback

So we use **Saga**.

---

# ğŸ§  2. The Core Problem (Why Saga Is Needed)

Imagine E-Commerce without Saga:

```
Order DB  â†’ Payment DB â†’ Inventory DB â†’ Shipping DB
```

Customer buys product.

### What if Payment succeeds but Inventory fails?

```
Money Deducted âŒ
Stock Not Available âŒ
Customer Angry âŒ
System Inconsistent âŒ
```

No automatic rollback.

ğŸ‘‰ This is where Saga comes in.

---

# ğŸ“Œ 3. What Does Saga Do?

Saga breaks **one big transaction** into **many small steps**.

Each step:

âœ… Has a normal operation
âœ… Has a rollback operation (compensation)

Example:

| Step      | Action          | Compensation    |
| --------- | --------------- | --------------- |
| Order     | Create Order    | Cancel Order    |
| Payment   | Deduct Money    | Refund          |
| Inventory | Reserve Stock   | Restore Stock   |
| Shipping  | Create Shipment | Cancel Shipment |

If any step fails â†’ previous steps are undone.

---

# ğŸ”„ 4. E-Commerce Example with Saga

### Normal Flow (Success âœ…)

```
1. Order Created
2. Payment Success
3. Stock Reserved
4. Shipment Created
```

Result:

```
Order = Confirmed
```

---

### Failure Flow (Compensation âŒ)

```
1. Order Created   âœ…
2. Payment Success âœ…
3. Stock Failed    âŒ
```

Now Saga activates rollback:

```
â†’ Refund Payment
â†’ Cancel Order
```

System becomes consistent again âœ…

---

# ğŸ“ 5. Two Types of Saga

There are **two main Saga styles**.

---

## âœ… 1ï¸âƒ£ Choreography Saga (Event-Based) â€“ Most Common

Services talk via events.

No central controller.

```
Order â†’ Event â†’ Payment â†’ Event â†’ Inventory â†’ Event â†’ Shipping
```

Each service listens and reacts.

### Example:

```
OrderCreated â†’ PaymentService
PaymentSuccess â†’ InventoryService
StockReserved â†’ ShippingService
```

If failure:

```
PaymentFailed â†’ OrderService
```

---

### ğŸ”¹ Diagram (Choreography)

```
Order â”€â”€â–¶ Kafka â”€â”€â–¶ Payment
   â–²                  â”‚
   â”‚                  â–¼
Cancel â—€â”€â”€ Kafka â—€â”€â”€ Inventory
```

âœ” Loosely coupled
âœ” Scalable
âœ” Best for Kafka systems

ğŸ‘‰ This is what you are using in your lab.

---

## âœ… 2ï¸âƒ£ Orchestration Saga (Central Controller)

One service controls everything.

```
Saga Manager â†’ Order
           â†’ Payment
           â†’ Inventory
           â†’ Shipping
```

Central brain decides next step.

---

### ğŸ”¹ Diagram (Orchestration)

```
        Saga Manager
             |
   ---------------------
   |     |     |      |
 Order Payment Stock Shipping
```

âœ” Easier logic
âŒ Single point of failure

Used in banking, workflows.

---

# ğŸ“Š 6. Comparison: Choreography vs Orchestration

| Feature        | Choreography | Orchestration |
| -------------- | ------------ | ------------- |
| Control        | Distributed  | Central       |
| Complexity     | Medium       | High          |
| Scaling        | Easy         | Hard          |
| Kafka Friendly | Yes          | Limited       |
| Failure Risk   | Low          | Higher        |

ğŸ‘‰ Microservices + Kafka â†’ Choreography is preferred.

---

# ğŸ§© 7. How Saga Works in Your Project

Your system uses **Choreography Saga**.

### Success Path

```
OrderService
  â†“ order-created
PaymentService
  â†“ payment-success
InventoryService
  â†“ stock-reserved
NotificationService
```

---

### Failure Path

```
OrderService
  â†“ order-created
PaymentService
  â†“ payment-failed
OrderService
  â†“ order-cancelled
```

That is Saga in action.

---

# âš™ï¸ 8. Technical Implementation (Conceptual)

### Step 1: Publish Normal Event

```csharp
Publish("payment-success");
```

---

### Step 2: Publish Failure Event

```csharp
Publish("payment-failed");
```

---

### Step 3: Compensation Handler

```csharp
if(event == "payment-failed")
{
   CancelOrder();
   Refund();
}
```

Each service handles its own rollback.

---

# ğŸ›¡ï¸ 9. Why Not Use Database Transactions?

Because in microservices:

âŒ Different databases
âŒ Different servers
âŒ Different owners

This is illegal:

```sql
BEGIN TRANSACTION
OrderDB + PaymentDB + StockDB
COMMIT
```

Not possible.

Saga is the alternative.

---

# ğŸ“‰ 10. Reliability with Saga

Saga gives:

âœ… No partial failures
âœ… Auto recovery
âœ… Business consistency
âœ… Fault tolerance

Without Saga:

```
Ghost Orders
Lost Money
Wrong Stock
Legal Issues
```

With Saga:

```
System Self-Heals
```

---

# ğŸ¯ 11. Interview-Ready Definition

> **Saga Pattern is a distributed transaction management pattern where each service executes a local transaction and publishes events to trigger the next step or compensation.**

Memorize this âœ…

---

# ğŸ“š 12. Real-Life Analogy (Easy for Students)

### Booking a Trip âœˆï¸

```
1. Book Flight
2. Book Hotel
3. Book Taxi
```

If Hotel fails:

```
Cancel Flight
Cancel Taxi
```

Thatâ€™s Saga.

No central transaction.

---

# ğŸ“Œ 13. Common Mistakes

| Mistake           | Result            |
| ----------------- | ----------------- |
| No compensation   | Data corruption   |
| No failure events | System stuck      |
| No idempotency    | Duplicate refunds |
| No logging        | Hard debugging    |

Always implement rollback logic.

---

# ğŸ§  14. When to Use Saga?

Use Saga when:

âœ… Multiple services
âœ… Multiple DBs
âœ… Business workflow
âœ… Money / Orders / Stock

Do NOT use Saga for:

âŒ Simple CRUD
âŒ Single DB apps

---

# ğŸ 15. One-Line Summary

> **Saga Pattern keeps microservices consistent by using events and compensating actions instead of database transactions.**

 



Here are the **key advantages of Kafka over RabbitMQ**, explained in a **practical, system-design way** (useful for teaching and real projects).

---

# âœ… 1. Kafka Is Built for **High-Volume Streaming**

### Kafka

âœ”ï¸ Handles **millions of messages per second**
âœ”ï¸ Designed for **big data + analytics + logs + events**

### RabbitMQ

âŒ Best for **lowâ€“medium traffic**
âŒ Slows down under massive streaming load

ğŸ“Œ **Result:**

> If your system produces huge data (e-commerce, IoT, logs, AI pipelines) â†’ Kafka wins.

---

# âœ… 2. Kafka Stores Data (Message Retention)

### Kafka = Message Log

Kafka **keeps messages for days/months**.

```
Todayâ€™s data â†’ still readable tomorrow
```

### RabbitMQ = Queue

RabbitMQ **deletes messages after consumption**.

```
Consumed â†’ Gone
```

ğŸ“Œ **Result:**

> Kafka = Replay + Audit + Debug
> RabbitMQ = One-time delivery

---

# âœ… 3. Kafka Supports Event Replay (Time Travel)

With Kafka, you can:

âœ”ï¸ Re-read old events
âœ”ï¸ Rebuild database
âœ”ï¸ Recover failures
âœ”ï¸ Train ML models

Example:

```
Replay last 7 days of orders
```

RabbitMQ âŒ cannot do this easily.

ğŸ“Œ **Result:**

> Kafka = Time Machine for data

---

# âœ… 4. Kafka Is Better for Microservices Event Architecture

Kafka is designed for:

âœ”ï¸ Event sourcing
âœ”ï¸ Saga
âœ”ï¸ CQRS
âœ”ï¸ Streaming pipelines

Example:

```
Order â†’ Payment â†’ Inventory â†’ Analytics â†’ AI
```

All can read same event.

RabbitMQ is more:

```
Producer â†’ Consumer (Point-to-Point)
```

ğŸ“Œ **Result:**

> Kafka = Nervous system
> RabbitMQ = Messenger

---

# âœ… 5. Kafka Has Built-in Scalability (Partitioning)

Kafka uses **Partitions**.

```
Topic â†’ Partition1
      â†’ Partition2
      â†’ Partition3
```

Each partition â†’ separate consumer.

So:

âœ”ï¸ Horizontal scaling
âœ”ï¸ Parallel processing
âœ”ï¸ Easy load balancing

RabbitMQ scaling is harder.

ğŸ“Œ **Result:**

> Kafka grows easily with traffic.

---

# âœ… 6. Kafka Is Better for Data Integration

Kafka works well with:

âœ”ï¸ Big Data
âœ”ï¸ Spark
âœ”ï¸ Flink
âœ”ï¸ Hadoop
âœ”ï¸ AI Pipelines
âœ”ï¸ Data Lakes

Example:

```
Orders â†’ Kafka â†’ Analytics â†’ Dashboard
```

RabbitMQ is not designed for this.

ğŸ“Œ **Result:**

> Kafka = Data backbone

---

# âœ… 7. Kafka Is More Durable (Crash Resistant)

Kafka writes data to disk in **append-only logs**.

So even if:

âŒ Server crashes
âŒ Power failure
âŒ Restart happens

Data is safe.

RabbitMQ mostly relies on memory + optional persistence.

ğŸ“Œ **Result:**

> Kafka = Better reliability for critical data

---

# âœ… 8. Kafka Supports Multiple Consumers Easily

Many services can read same topic:

```
Order Topic
  â†“
Payment
Inventory
Email
Analytics
AI
```

Each gets full data.

RabbitMQ needs special fanout setup.

ğŸ“Œ **Result:**

> Kafka = Natural broadcast system

---

# âœ… 9. Kafka Fits Cloud + Enterprise Scale Better

Large companies prefer Kafka for:

âœ”ï¸ Netflix
âœ”ï¸ Uber
âœ”ï¸ Amazon
âœ”ï¸ LinkedIn
âœ”ï¸ Flipkart

Because:

* Massive scale
* Fault tolerance
* Streaming

RabbitMQ is more popular in small/medium systems.

---

# âœ… 10. Performance: Kafka Is Faster at Scale

| Feature    | Kafka     | RabbitMQ |
| ---------- | --------- | -------- |
| Throughput | Very High | Medium   |
| Latency    | Low       | Low      |
| Storage    | Yes       | Limited  |
| Replay     | Yes       | No       |
| Streaming  | Excellent | Weak     |

ğŸ“Œ **Result:**

> Kafka = Speed + Volume
> RabbitMQ = Simplicity

---

# ğŸ“Š Summary Table

| Area          | Kafka Advantage    |
| ------------- | ------------------ |
| Traffic       | Handles huge loads |
| Storage       | Keeps messages     |
| Replay        | Yes                |
| Scaling       | Easy               |
| Analytics     | Built-in support   |
| Microservices | Event-first        |
| Reliability   | Very high          |
| Broadcasting  | Native             |

---

# ğŸ“ Mentor Explanation (For Students)

You can explain like this:

### ğŸšŒ RabbitMQ = Courier Service

```
Send â†’ Deliver â†’ Done
```

* Good for tasks
* Simple
* Fast delivery
* No history

---

### ğŸš„ Kafka = Railway System

```
Data â†’ Stored â†’ Replayed â†’ Shared
```

* Carries huge data
* Keeps history
* Many users
* Long-term system

---

# ğŸ§  When Should You Choose Kafka?

Use Kafka when you need:

âœ… Event-driven microservices
âœ… Saga pattern
âœ… Analytics
âœ… Logging
âœ… Data pipelines
âœ… AI/ML inputs
âœ… Audit trail
âœ… Large scale

---

# ğŸ§  When RabbitMQ Is Better

RabbitMQ is better when:

âœ… Simple job queues
âœ… Email sending
âœ… Background tasks
âœ… Notifications
âœ… Small systems

---

# ğŸ Final Answer (One Line)

> Use **Kafka** when you are building a **data-driven, scalable, event-based system**.
> Use **RabbitMQ** when you need a **simple message queue**.

 
